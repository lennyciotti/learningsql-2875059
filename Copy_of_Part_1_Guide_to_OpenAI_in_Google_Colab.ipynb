{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lennyciotti/learningsql-2875059/blob/main/Copy_of_Part_1_Guide_to_OpenAI_in_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Guide to OpenAI in Google Colab\n",
        "\n",
        "Welcome to **Part 1: Guide to OpenAI in Google Colab**. In this notebook, you‚Äôll learn the fundamentals of **prompt engineering** through a step-by-step tutorial. By the end, you‚Äôll be able to:\n",
        "\n",
        "- Create and store an OpenAI API key  \n",
        "- Apply core prompt engineering strategies (iteration and refinement)  \n",
        "- Use practical coding patterns to streamline your workflow  \n",
        "\n",
        "These skills are not only valuable for this project, but they will also help you stand out in industry. In fact, Andrew Ng [notes](https://www.linkedin.com/posts/andrewyng_there-is-significant-unmet-demand-for-developers-activity-7369397355160272898-i85T?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAUuuFIBPjBR1kCVBdoY03J3r6hwaAwvapU) that some of the key abilities he looks for when interviewing AI engineers include:  \n",
        "\n",
        "- Using AI building blocks like prompting, RAG, evals, agentic workflows, and machine learning to build applications  \n",
        "- Prototyping and iterating rapidly  \n",
        "\n",
        "You‚Äôll get to practice both of these in this workshop.  \n",
        "\n",
        "Let‚Äôs dive in and start building! üöÄ\n",
        "\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "h0D-mCSmF4fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. **[Getting Started](#getting-started)**\n",
        "\n",
        "    - Creating an OpenAI Key\n",
        "\n",
        "    - Saving Your API Key in Colab\n",
        "\n",
        "    - Loading and Verifying Your API Key\n",
        "\n",
        "\n",
        "2. **[API Fundamentals](#api-fund)**\n",
        "\n",
        "    -  Temperature\n",
        "\n",
        "    -  System/User Role Prompting\n",
        "\n",
        "3. **[Practical Tips](#practical-tips)**\n",
        "\n",
        "    - Prompt Engineering Basics\n",
        "\n",
        "    - Don‚Äôt Repeat Yourself (DRY) Programming - Creating Functions\n",
        "\n",
        "    - Markdown Formatting\n",
        "\n",
        "4. **[Forward](#forward)**\n",
        "\n",
        "\n",
        "\n",
        "-----\n"
      ],
      "metadata": {
        "id": "a3TFltMM6-BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"getting-started\"></a>\n",
        "\n",
        "## 1. Getting Started\n",
        "\n",
        "\n",
        "In this section, we‚Äôll get started with OpenAI‚Äôs API ‚Äî learning how to obtain and verify your API key, and how to write your first prompt.  \n"
      ],
      "metadata": {
        "id": "9DOXu1ULLQ-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an OpenAI Key üîë"
      ],
      "metadata": {
        "id": "qLlgbzBNgVQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: OpenAI  \n",
        "\n",
        "Click this link to open [OpenAI](https://openai.com/). In the top-right corner, hover over **Log In** and select **API Platform**, as shown in the image below.  \n"
      ],
      "metadata": {
        "id": "NcAUE-qhMoqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_1.png?raw=true\">"
      ],
      "metadata": {
        "id": "SWmQGCh95aah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Authentication  \n",
        "\n",
        "After signing in (and entering the verification code sent to your email), you will be directed to the page shown below. Under **Authentication**, click <u>Organization settings</u>.  \n"
      ],
      "metadata": {
        "id": "8ai80iO7MtjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_2.png?raw=true\">"
      ],
      "metadata": {
        "id": "fvmIkb_K5dQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Creating a New Secret Key  \n",
        "\n",
        "After clicking <u>Organization settings</u>, you will be taken to the page shown below. From there, click **Create new secret key**.  \n"
      ],
      "metadata": {
        "id": "9ASw4lDf4qSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_3.png?raw=true\">"
      ],
      "metadata": {
        "id": "mAKiVFJ_5Bvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Creating the Key  \n",
        "\n",
        "After clicking **Create new secret key**, a pop-up will appear. While entering a name is optional, it is recommended to use something meaningful (e.g., *Fall 2025 Practicum*). Next, select **Default project** and ensure **All** is selected. Finally, click **Create secret key**.  \n"
      ],
      "metadata": {
        "id": "3aT5Qh835c1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_4.png?raw=true\">"
      ],
      "metadata": {
        "id": "-ZbPe1Rz557Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Saving Your Key  \n",
        "\n",
        "After creating the key, it will appear as shown below (mine is hidden for privacy).  \n",
        "\n",
        "1. Click **Copy** and save your key somewhere safe‚Äîyou won‚Äôt be able to view it again later.  \n",
        "2. Do **not** share your key. Using an OpenAI key incurs costs, and you will be charged if someone else uses it.  "
      ],
      "metadata": {
        "id": "MfzG8I2V5b0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_5.png?raw=true\">"
      ],
      "metadata": {
        "id": "Qdi0Mg3_56wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next Steps\n",
        "\n",
        "Congrats! You now made your OpenAI Key. Now, this is where the fun part begins. We can finally utilize the key.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "YGNlDDkN5w1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving Your API Key in Colab üîë\n",
        "\n",
        "Before using OpenAI's API, we need a secure way to store the API key in this notebook.  \n",
        "Google Colab provides a built-in secrets manager for this purpose.  \n",
        "\n",
        "\n",
        "#### Step 1:\n",
        "On the left sidebar, click on the **key icon**.  \n",
        "\n",
        "#### Step 2:\n",
        "Click **‚ÄúAdd new secret.‚Äù**  \n",
        "\n",
        "#### Step 3:\n",
        "- Paste your API key into the **Value** field  \n",
        "- Give it a descriptive **Name** (e.g., `OPENAI_API_KEY`)  \n",
        "- Ensure **Notebook access** is enabled  \n"
      ],
      "metadata": {
        "id": "Bu1FZjF_62yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_6.png?raw=true\" width=\"500\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "GVvXAhCE-3MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Once entered, you can hit the exit button. Your API key will be  stored automatically and available for use in your notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "nqBl6zeD-2Gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Loading and Verifying Your API Key üîë\n",
        "\n",
        "We load the API key from Colab Secrets into an environment variable so Python packages can access it.  \n",
        "The check then verifies whether `OPENAI_API_KEY` is set:  \n",
        "\n",
        "- If the key is missing, a clear **RuntimeError** is raised so you know to add it in Colab Secrets.  \n",
        "- If the key is found, it safely confirms with `True` without ever printing the actual secret.  \n",
        "\n",
        "However, before we do this, we must import `openai`'s library.\n",
        "\n",
        "<br>  \n",
        "\n",
        "**‚ú® Optional Learning**  \n",
        "- `google.colab.userdata`: Secure interface to Colab‚Äôs Secrets; lets you fetch saved keys (e.g., `userdata.get(\"OPENAI_API_KEY\")`).  \n",
        "- `os`: Standard library module for interacting with the operating system ‚Äî here, used to read/set environment variables (`os.getenv`, `os.environ`).  "
      ],
      "metadata": {
        "id": "ISid8s8DDBKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "hHEhlVltMWup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Pull your saved secret into an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Test if the key is available (without printing it)\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise RuntimeError(\"OPENAI_API_KEY is not set. Add it via Colab Secrets (üîë) and try again.\")\n",
        "else:\n",
        "    print(\"Key loaded?\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dxACnFdC8Nj",
        "outputId": "fe65aae7-e5fd-4c0f-c572-e581b049b8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key loaded? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "If you see `Key loaded? True`, then everything is working and you‚Äôre ready to move on to the next step.  \n",
        "\n",
        "<br>\n",
        "\n",
        "If you see the error, please make sure that:  \n",
        "- You saved your API key in Colab‚Äôs **üîë Secrets** panel.  \n",
        "- The secret is named exactly **`OPENAI_API_KEY`** (no typos or extra spaces).  \n",
        "\n"
      ],
      "metadata": {
        "id": "nErn9WnmH8KT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congrats! If you have successfully loaded in your key, you will run your first **end-to-end test with the OpenAI API** ‚Äî creating a client, sending a simple prompt, and viewing the model‚Äôs reply.  \n",
        "\n",
        "The first line\n",
        "\n",
        "```python\n",
        "client = OpenAI()\n",
        "```\n",
        "\n",
        "Creates an OpenAI client that knows how to talk to the API. It automatically picks up your API key from `OPENAI_API_KEY`, which you saved earlier in Colab‚Äôs Secrets.\n",
        "\n",
        "The next three lines:\n",
        "\n",
        "```python\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"\n",
        ")\n",
        "```\n",
        "\n",
        "- Sends a **request** to the Responses API\n",
        "- `model=\"gpt-4o-mini\"` selects the model\n",
        "- `input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"` is your prompt\n",
        "- The full structured result (text + metadata) is stored in `resp`\n",
        "\n",
        "Finally:\n",
        "\n",
        "```python\n",
        "print(resp.output_text)\n",
        "```\n",
        "\n",
        "Extracts just the generated text from the response object and prints it.\n",
        "\n",
        "<br>\n",
        "\n",
        "That‚Äôs it! We follow this process: create a client ‚Üí send a prompt ‚Üí print the model‚Äôs reply."
      ],
      "metadata": {
        "id": "115lW5IyJS4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()  # uses OPENAI_API_KEY already in your env\n",
        "\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu1AeBQBC_0o",
        "outputId": "e9be9f58-f2ba-4dd3-a6ef-c665eeb1e506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are some effective study tips:\n",
            "\n",
            "1. **Set Clear Goals**: Define what you want to achieve in each study session. Specific goals help you stay focused and motivated.\n",
            "\n",
            "2. **Create a Study Schedule**: Allocate specific time slots for studying different subjects. Consistency helps reinforce learning.\n",
            "\n",
            "3. **Use Active Learning Techniques**: Engage with the material through summarizing, questioning, or teaching others. This enhances retention.\n",
            "\n",
            "4. **Take Regular Breaks**: Implement the Pomodoro Technique‚Äîstudy for 25 minutes, then take a 5-minute break. This keeps your mind fresh.\n",
            "\n",
            "5. **Stay Organized**: Keep your study materials and notes well-organized. Clutter can distract and hinder productivity.\n",
            "\n",
            "6. **Find Your Ideal Study Environment**: Choose a quiet, comfortable place with minimal distractions. A good environment enhances focus.\n",
            "\n",
            "7. **Utilize Various Resources**: Incorporate videos, podcasts, and books to get diverse perspectives on the material.\n",
            "\n",
            "8. **Practice with Flashcards**: Create flashcards for key concepts and terminology. They‚Äôre great for quick reviews and self-testing.\n",
            "\n",
            "9. **Join Study Groups**: Collaborating with peers can provide new insights and help clarify difficult concepts through discussion.\n",
            "\n",
            "10. **Stay Healthy**: Don‚Äôt forget to nourish your body. Regular exercise, hydration, and proper sleep improve cognitive function and concentration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "<a name=\"api-fund\"></a>\n",
        "\n",
        "\n",
        "## 2. API Fundamentals\n",
        "\n",
        "In this section, we‚Äôll cover two core features of the API: **temperature** and **system/user role prompting**. Let‚Äôs dive in!\n"
      ],
      "metadata": {
        "id": "zQ7C2P5KQz4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature  \n",
        "\n",
        "One parameter you can adjust in the model is the [temperature](https://platform.openai.com/docs/faq/how-should-i-set-the-temperature-parameter#how-should-i-set-the-temperature-parameter), which controls the **randomness** of its output.  \n",
        "\n",
        "- A value near **0** ‚Üí more deterministic and consistent responses.  \n",
        "- A value near **1.0** ‚Üí more varied and creative responses.  \n",
        "- The maximum allowed is **2.0**.  \n",
        "\n",
        "If you‚Äôd like to dive deeper, check out [this article on LLM temperature](https://www.hopsworks.ai/dictionary/llm-temperature). *(Optional reading)*  \n",
        "\n",
        "Now let‚Äôs experiment! We‚Äôll assign GPT the **system role** of a creative poet and request a **4-line poem about rain**. Then we‚Äôll compare outputs at different temperatures:  \n",
        "\n",
        "- Default setting: **1.0**  \n",
        "- Low randomness: **0.2**  \n",
        "- High randomness: **1.8**  \n",
        "\n",
        "To observe the effect, we‚Äôll call the API **3 times for each temperature** in a [loop](https://www.w3schools.com/python/python_for_loops.asp). A short pause of 10 seconds (`time.sleep(10)`) between calls prevents hitting API rate limits.  \n",
        "\n"
      ],
      "metadata": {
        "id": "xJHSBsayqjUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tip**\n",
        "\n",
        "Store your prompt as a [string](https://www.w3schools.com/python/python_strings.asp) variable before passing it into the model.  \n"
      ],
      "metadata": {
        "id": "JFPHi04orgJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"You are a creative poet. \"\n",
        "    \"Write a short 4-line poem about rain.\"\n",
        ")"
      ],
      "metadata": {
        "id": "ZfnfLZWjqiRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Temperature `1.0`"
      ],
      "metadata": {
        "id": "2ht2xhEfmSx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=1.) ‚Äî\")\n",
        "    resp = client.responses.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        input=prompt,\n",
        "        temperature=0.2\n",
        "    )\n",
        "    print(resp.output_text)\n",
        "\n",
        "    if i < 2:\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8tUj9h1qiUu",
        "outputId": "a6309d28-c236-4345-9a01-db2f4560889c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=0.2) ‚Äî\n",
            "Whispers of silver dance on the ground,  \n",
            "Nature's soft sigh, a soothing sound.  \n",
            "Each droplet a story, a moment in time,  \n",
            "In the heart of the storm, the world starts to rhyme.\n",
            "\n",
            "‚Äî Run 2 (temp=0.2) ‚Äî\n",
            "Whispers fall from silver skies,  \n",
            "Dancing drops in soft reprise,  \n",
            "Nature's tears, a sweet embrace,  \n",
            "Life awakens, finds its place.\n",
            "\n",
            "‚Äî Run 3 (temp=0.2) ‚Äî\n",
            "Whispers of silver in the twilight sky,  \n",
            "Dancing on rooftops, a soft lullaby.  \n",
            "Each droplet a story, a moment to share,  \n",
            "Nature's embrace in the cool, fragrant air.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Analysis**\n",
        "\n",
        "These three poems at temperature = 1.0 show a balance of variety and consistency. Each output uses gentle, predictable imagery, but the phrasing and rhythm shift slightly with each run. This illustrates how the default temperature produces outputs that are creative yet still fairly stable across generations."
      ],
      "metadata": {
        "id": "P1RKaz3AnQd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Temperature `0.2`"
      ],
      "metadata": {
        "id": "OR9m-nLQmnjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=0.2) ‚Äî\")\n",
        "    resp = client.responses.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        input=prompt,\n",
        "        temperature=0.2\n",
        "    )\n",
        "    print(resp.output_text)\n",
        "\n",
        "    if i < 2:\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq_tAfDaqiXw",
        "outputId": "1b36dd00-ebb4-4ab6-a432-4c56fdd1a149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=0.2) ‚Äî\n",
            "Whispers of silver in the twilight sky,  \n",
            "Dancing on rooftops, a soft lullaby.  \n",
            "Each drop a secret, a story untold,  \n",
            "Nature's embrace in a shimmer of gold.\n",
            "\n",
            "‚Äî Run 2 (temp=0.2) ‚Äî\n",
            "Whispers of silver dance on the ground,  \n",
            "Nature's soft lullaby, a soothing sound.  \n",
            "Each drop a secret, a story untold,  \n",
            "In the arms of the storm, the world turns to gold.\n",
            "\n",
            "‚Äî Run 3 (temp=0.2) ‚Äî\n",
            "Whispers of silver dance on the ground,  \n",
            "Nature's soft sigh, a soothing sound.  \n",
            "Each droplet a story, a memory spun,  \n",
            "In the heart of the storm, new life has begun.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Analysis**\n",
        "\n",
        "At temperature = 0.2, the poems are highly consistent, often reusing imagery like *‚Äúwhispers of silver‚Äù* and *‚Äúdancing droplets‚Äù* (though results may still vary). The structure and tone remain nearly identical across runs, showing how a low temperature makes the model more deterministic and less creative. The outputs feel polished but display less variety compared to higher settings.\n"
      ],
      "metadata": {
        "id": "4t-Au9nEnP0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Temperature `1.8`"
      ],
      "metadata": {
        "id": "Ngb_ai56nIQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=1.8) ‚Äî\")\n",
        "    resp = client.responses.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        input=prompt,\n",
        "        temperature=1.8\n",
        "    )\n",
        "    print(resp.output_text)\n",
        "\n",
        "    if i < 2:\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2W9-bb6nIrF",
        "outputId": "b0bd1157-50b8-439e-dbcb-3435c49c2f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=1.8) ‚Äî\n",
            "Gentle whispers from the sky,  \n",
            "Dancing droplets; trees reply,  \n",
            "Nature bathes in silver streams,  \n",
            "Splashing dreams like glimmering seams.  \n",
            "\n",
            "‚Äî Run 2 (temp=1.8) ‚Äî\n",
            "Bare leaves sway in whispers stray,  \n",
            "Dancing drops turn night to day,  \n",
            "Mother Earth's rerun tonight,  \n",
            "Healing tears ignite delight.\n",
            "\n",
            "‚Äî Run 3 (temp=1.8) ‚Äî\n",
            "Whispers of water dance from the sky,  \n",
            "Each drop a melody‚ÄÜ‚Äî quick to comply.  \n",
            "Kissing the earth, a soothing refrain,  \n",
            "In gray embrace, the world cries in rain.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Analysis**\n",
        "\n",
        "At temperature = 1.8, the poems show greater variety and imaginative phrasing. The imagery shifts noticeably between runs, with less repetition and more surprising word choices. This illustrates how a high temperature boosts creativity and randomness, though it can also produce less polished or less consistent results.\n"
      ],
      "metadata": {
        "id": "dtvh6flDnPXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Try It Yourself\n",
        "\n",
        "Now that you‚Äôve seen the flow and output, experiment with temperature! Set it to **0.0** for deterministic, minimal-variation answers; try **2.0** for very diverse, creative outputs (may be less consistent)."
      ],
      "metadata": {
        "id": "w9zle1esnhYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UNCOMMENT BELOW AND ENTER A TEMPERATURE VALUE\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=() ‚Äî\")\n",
        "    resp = client.responses.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        input=prompt,\n",
        "        temperature=ENTER_VALUE  # üëà replace with your chosen temperature\n",
        "    )\n",
        "    print(resp.output_text)\n",
        "\n",
        "    if i < 2:\n",
        "        time.sleep(10)  # pause between runs\n"
      ],
      "metadata": {
        "id": "ccQhL8EhoJQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System/User Role Prompting\n",
        "\n",
        "Now, we will talk about **System/User Role Prompting**. But before diving in, let‚Äôs quickly review **Role Prompting**.  \n",
        "\n",
        "**Role prompting** is a way of shaping not just *what* the model says, but *how* it says it. By assigning the model a role, you can influence its tone, perspective, and style of response.  \n",
        "\n",
        "For example, if you tell the model *‚ÄúYou are a supportive tutor,‚Äù* it will answer with encouragement. If you instead say *‚ÄúYou are a strict tutor,‚Äù* the output will sound more demanding.  \n",
        "\n",
        "Here is an example of **Role Prompting** only."
      ],
      "metadata": {
        "id": "XYMNMYMZvos6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encouraging_prompt = (\n",
        "    \"You are an encouraging tutor. Use supportive and positive language. \"\n",
        "    \"Adopt this encouraging voice consistently in every tip.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip must be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** Celebrate progress by testing yourself with short quizzes on sampling and probability after each session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, written in the same format but with the encouraging tone.\\n\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "97tujxHDKQhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input= encouraging_prompt\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7SUtH5dKQH2",
        "outputId": "db7727c7-4649-47d3-f386-76809b439f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolutely! Here are three more supportive study tips for your statistics journey:\n",
            "\n",
            "- **Visual Aids:** Create colorful charts and graphs to solidify your understanding of hypothesis testing‚Äîvisuals make concepts more memorable!\n",
            "\n",
            "- **Study Groups:** Join or form a study group to discuss and practice key concepts like distribution shapes‚Äîcollaboration enhances learning and boosts confidence!\n",
            "\n",
            "- **Real-Life Applications:** Relate statistical concepts to real-world examples, like sports statistics, to make learning engaging and relevant‚Äîyou're doing great!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! We created a structured and detailed prompt tailored for our audience of introductory statistics students, and we instructed the model to use an encouraging tone.  \n",
        "\n",
        "That prompt works well, but we can organize it more clearly. The API supports this by separating instructions into structured **role messages**:\n",
        "\n",
        "- **System** ‚Üí defines the overall role, voice, or behavior (e.g., ‚ÄúYou are a supportive tutor‚Äù).  \n",
        "- **User** ‚Üí contains the actual request (e.g., ‚ÄúGive me 3 concise study tips for intro statistics‚Äù).  \n",
        "\n",
        "This separation keeps prompts cleaner, makes intent more explicit, and helps the model maintain consistency in longer conversations.  \n"
      ],
      "metadata": {
        "id": "-pVdtJGkKLRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an encouraging tutor. Be supportive, practical, and foster collaboration.\"\n",
        "user_message = (\n",
        "    \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx_PxM7xJEck",
        "outputId": "d84f6540-f985-40cd-cdb4-161ebe497a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Practice Problems:** Regularly solve a variety of problems on hypothesis testing to solidify your understanding of concepts and calculations.  \n",
            "- **Visual Aids:** Create visual representations, like graphs, for distributions and data sets to enhance comprehension and retention.  \n",
            "- **Group Study:** Collaborate with classmates to discuss real-world applications of statistical methods, boosting understanding through diverse perspectives.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "<a name=\"practical-tips\"></a>\n",
        "\n",
        "\n",
        "## 3. Practical Tips\n",
        "\n",
        "In this section, we will go over some practical tips that will be helpful as you embark throughout this module!"
      ],
      "metadata": {
        "id": "JOk4bHevTtqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Prompt Engineering   \n",
        "\n",
        "In the System/User Role Prompting section, we briefly touched on what makes a good prompt. Now let‚Äôs dive a little deeper into some key strategies for effective prompt design. Let's start with an example of a **fluffy** prompt.\n"
      ],
      "metadata": {
        "id": "oJWnJsB4O7to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me three study tips.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7yhFEkZKp7k",
        "outputId": "4a9d28e6-7a0a-460b-a774-bc7bab77909d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are three effective study tips:\n",
            "\n",
            "1. **Active Learning**: Engage with the material beyond passive reading. Summarize information in your own words, create flashcards, or teach concepts to someone else. This helps reinforce what you've learned.\n",
            "\n",
            "2. **Pomodoro Technique**: Use a timer to break your study sessions into manageable chunks (e.g., 25 minutes of focused study followed by a 5-minute break). This method helps maintain concentration and reduces burnout.\n",
            "\n",
            "3. **Organized Environment**: Create a clutter-free and distraction-free study space. Having a dedicated area for studying can improve focus and make your study sessions more productive.\n",
            "\n",
            "Implementing these tips can enhance your learning efficiency!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the output may look fine, it leaves too much room for interpretation ‚Äî we only instructed the model to ‚Äúgive us three study tips.‚Äù Without further context, this could apply to any subject, any student group, or any learning scenario. In addition, we gave no specifications about length or output style, so the model had freedom to choose its own format and tone. This lack of clarity makes the results less predictable and harder to tailor to our needs.  \n",
        "\n",
        "Let's contrast or fluffy prompt with with the one we made for our encouraring tutor:\n",
        "\n"
      ],
      "metadata": {
        "id": "lm1H8U0BWQDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "\n",
        "encouraging_prompt = (\n",
        "    \"You are an encouraging tutor. Use supportive and positive language. \"\n",
        "    \"Adopt this encouraging voice consistently in every tip.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip must be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** Celebrate progress by testing yourself with short quizzes on sampling and probability after each session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, written in the same format but with the encouraging tone.\\n\"\n",
        ")\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "mF1CKd-bYS0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This prompt is much better for the following reasons:\n",
        "\n",
        "- **Precise**: It specifies the subject (introductory statistics) and the type of content (study tips), reducing ambiguity.  \n",
        "- **Set Boundaries**: It defines clear limits on number of tips (3) and sentence length (‚â§ 20 words).  \n",
        "- **Controlled Format**: It requires bullet points and even provides an example to ensure structural consistency.  \n",
        "- **Guided Style**: It enforces an encouraging tone, making the output more suitable for the intended audience.  \n",
        "\n",
        "\n",
        "These adjustments highlight the power of prompt engineering ‚Äî giving us much greater control over the **length, style, and clarity** of the output. Remember, this is an iterative process - each step builds on the last, and small adjustments to your instructions can lead to big improvements in the model‚Äôs output.   \n"
      ],
      "metadata": {
        "id": "Cq7We6qTYR-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Don‚Äôt Repeat Yourself (DRY) Programming - Creating Functions\n",
        "\n",
        "By now, you‚Äôve probably noticed that we‚Äôre repeating the same code again and again. That‚Äôs not very efficient!  \n",
        "\n",
        "To fix this, we can create a **function**. Functions are a staple in programming and data science ‚Äî they let you **bundle code into a reusable block**. Instead of copying and pasting the same lines, you simply call the function by name whenever you need it.  \n",
        "\n",
        "This makes your code **cleaner, more efficient, and easier to maintain** as your project grows.  \n",
        "\n",
        "We will call our first function, `generate_text_simple`. Inside our function, we have\n",
        "\n",
        "```python\n",
        "resp = client.responses.create(\n",
        "    model=model,\n",
        "    input=prompt\n",
        ")\n",
        "\n",
        "return resp.output_text\n",
        "```\n",
        "\n",
        "Inside the function, we accept two arguments ‚Äî the **prompt** and an optional **model** (default: `\"gpt-4o-mini\"`). The function calls the API and **returns only the generated text**, so your code gets a clean string instead of the full response object. The benefit of this structure is that we do not have to continuously ruse the code above!\n"
      ],
      "metadata": {
        "id": "eLUf3jOyc4e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encouraging_prompt = (\n",
        "    \". Use supportive and positive language. \"\n",
        "    \"Adopt this encouraging voice consistently in every tip.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip must be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** Celebrate progress by testing yourself with short quizzes on sampling and probability after each session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, written in the same format but with the encouraging tone.\\n\"\n",
        ")\n",
        "\n",
        "role = \"You are an encouraging tutor\""
      ],
      "metadata": {
        "id": "RbkWhxPqFZPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(prompt: str,  role: str, model: str = \"gpt-4o-mini\" ) -> str:\n",
        "    \"\"\"\n",
        "    Send a prompt to an OpenAI model and return the generated text.\n",
        "\n",
        "    Args:\n",
        "        prompt: The input text/prompt.\n",
        "        model:  The model name to use (default: gpt-4o-mini).\n",
        "\n",
        "    Returns:\n",
        "        The model's text output.\n",
        "    \"\"\"\n",
        "\n",
        "    full_prompt = role + prompt\n",
        "    resp = client.responses.create(\n",
        "        model=model,\n",
        "        input=full_prompt\n",
        "\n",
        "    )\n",
        "    return resp.output_text\n",
        "print(generate_text_simple(\"Give me exactly 3 study tips for students in a college-level introductory statistics course\", \"you are a very stern mean professor\"))"
      ],
      "metadata": {
        "id": "EegVxTPBVBN2",
        "outputId": "1f3def4f-e6e5-4755-8428-e5f275f0f094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly. Here are three essential study tips for excelling in your introductory statistics course:\n",
            "\n",
            "1. **Master the Fundamentals**: Ensure you have a solid understanding of basic mathematical concepts. Statistics relies heavily on algebra, so review operations with decimals, fractions, and exponents. Familiarize yourself with common statistical terms and formulas.\n",
            "\n",
            "2. **Engage with the Material**: Don‚Äôt just passively read the textbook. Work through examples and problem sets; apply the concepts to real-world scenarios. Join study groups or attend office hours to clarify difficult topics and engage in discussions that deepen your understanding.\n",
            "\n",
            "3. **Practice, Practice, Practice**: Statistics requires a lot of practice to become proficient. Regularly solve practice problems and take advantage of any quizzes or practice tests provided by your instructor. The more you practice, the more comfortable you'll become with the different types of problems you'll encounter. \n",
            "\n",
            "Remember, mere attendance and passive reading will not suffice. You must actively participate in your learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets show this function with the encouraging and harsh tips that we created in the previous section!\n",
        "\n",
        "**Tip:** For cleaner formatting of the output, wrap the function call inside a `print()` statement.  \n"
      ],
      "metadata": {
        "id": "eWNwtKEHRvUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encouaring_tips = generate_text_simple(encouraging_prompt)\n",
        "print(encouaring_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ynySxblN09I",
        "outputId": "50f39bcb-cef6-4395-95e3-04af439cc87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Visual Aids:** Enhance your understanding by creating colorful charts or graphs to represent data distributions and probability concepts.  \n",
            "\n",
            "- **Study Groups:** Collaborate with classmates to discuss hypothesis testing, fostering deeper comprehension and building lasting friendships.  \n",
            "\n",
            "- **Practice Problems:** Regularly tackle a variety of exercises on inferential statistics to strengthen your skills and boost your confidence!  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See! This is much more efficient than repeatedly calling `client.responses.create(model=model, input=prompt)` in every cell.\n",
        "\n"
      ],
      "metadata": {
        "id": "64i1lxc-QD9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Markdown Formatting  \n",
        "\n",
        "So far, we have seen the LLM's raw output. However, we can make our results more readable by asking the model to format responses in **Markdown**. This will help us generate outputs that look cleaner and are easier to interpret inside Colab or on GitHub. This is especially useful when working with structured content such as study guides, rubrics, or summaries.\n",
        "\n",
        "We can create a function called `to_markdown`, which we will call whenever we want to render the model‚Äôs text as formatted Markdown (headings, lists, bold/italics) instead of plain text.\n"
      ],
      "metadata": {
        "id": "p0QO78dcLxyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    # Convert the provided text to Markdown format for better display in Jupyter Notebooks\n",
        "    return Markdown(text)"
      ],
      "metadata": {
        "id": "aEVCoqPhOQvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it out with the `encouaring_tips` variable we just created!"
      ],
      "metadata": {
        "id": "mWN_i6iTWukY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(encouaring_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "3EDQFXHhwR-D",
        "outputId": "d725fbc0-5179-460b-cb30-5b4a5d0a3780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Visual Aids:** Enhance your understanding by creating colorful charts or graphs to represent data distributions and probability concepts.  \n\n- **Study Groups:** Collaborate with classmates to discuss hypothesis testing, fostering deeper comprehension and building lasting friendships.  \n\n- **Practice Problems:** Regularly tackle a variety of exercises on inferential statistics to strengthen your skills and boost your confidence!  "
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See! Our output is much cleaner!\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "XI551XFMw4-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"forward\"></a>\n",
        "\n",
        "## 4. Forward  \n",
        "\n",
        "Congrats! You now have the basics of prompt engineering. üéâ  \n",
        "Next, we‚Äôll apply these skills to a real use case ‚Äî showing how LLMs can generate an essay, design a rubric, and then grade the essay based on that rubric.  \n"
      ],
      "metadata": {
        "id": "kuF1QiUE7yae"
      }
    }
  ]
}